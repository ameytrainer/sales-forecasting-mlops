{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ’¾ Notebook 5: DVC Data Versioning\n",
    "\n",
    "**Author:** Amey Talkatkar | **Course:** MLOps with Agentic AI\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "- Initialize DVC in your project\n",
    "- Track datasets with DVC\n",
    "- Push/pull data from remote storage (DagsHub)\n",
    "- Switch between data versions\n",
    "- Create DVC pipelines\n",
    "- Integrate DVC with Git\n",
    "\n",
    "## ðŸ”¥ The Problem\n",
    "You have:\n",
    "- `sales_data_v1.csv` (January data)\n",
    "- `sales_data_v2.csv` (added February)\n",
    "- `sales_data_final.csv` (added March)\n",
    "- `sales_data_final_v2.csv` (fixed bugs)\n",
    "- `sales_data_actually_final.csv` (really final!)\n",
    "\n",
    "Which version trained the production model? **Nobody knows!** ðŸ˜±\n",
    "\n",
    "**DVC Solution:** One file name, infinite versions tracked in Git!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "âš ï¸ **Note:** This notebook demonstrates DVC commands. Most commands need to be run in terminal, not in notebook cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "# Change to project root\n",
    "os.chdir('..')\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initialize DVC\n",
    "\n",
    "Run in terminal:\n",
    "```bash\n",
    "cd ~/sales-forecasting-mlops\n",
    "dvc init\n",
    "```\n",
    "\n",
    "This creates:\n",
    "- `.dvc/` directory (DVC configuration)\n",
    "- `.dvcignore` file (like .gitignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if DVC is initialized\n",
    "if os.path.exists('.dvc'):\n",
    "    print(\"âœ… DVC already initialized\")\n",
    "else:\n",
    "    print(\"âŒ DVC not initialized. Run: dvc init\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Add Data to DVC\n",
    "\n",
    "Track your dataset with DVC:\n",
    "\n",
    "```bash\n",
    "dvc add data/raw/sales_data.csv\n",
    "```\n",
    "\n",
    "This creates:\n",
    "- `data/raw/sales_data.csv.dvc` (metadata file - track in Git)\n",
    "- Updates `data/raw/.gitignore` (ignore actual data)\n",
    "- Moves data to `.dvc/cache/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate dvc add\n",
    "data_file = 'data/raw/sales_data.csv'\n",
    "dvc_file = f'{data_file}.dvc'\n",
    "\n",
    "if os.path.exists(dvc_file):\n",
    "    print(f\"âœ… {dvc_file} exists\")\n",
    "    \n",
    "    # Read .dvc file\n",
    "    with open(dvc_file, 'r') as f:\n",
    "        print(\"\\nðŸ“„ Contents of .dvc file:\")\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(f\"âŒ Run: dvc add {data_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Commit to Git\n",
    "\n",
    "Add .dvc file to Git (NOT the data!):\n",
    "\n",
    "```bash\n",
    "git add data/raw/sales_data.csv.dvc data/raw/.gitignore\n",
    "git commit -m \"Add sales data v1 with DVC\"\n",
    "```\n",
    "\n",
    "Now Git tracks:\n",
    "- âœ… `.dvc` file (123 bytes)\n",
    "- âŒ `.csv` file (2 MB) - ignored!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Configure DVC Remote (DagsHub)\n",
    "\n",
    "Set up remote storage:\n",
    "\n",
    "```bash\n",
    "# Add DagsHub as remote\n",
    "dvc remote add origin https://dagshub.com/YOUR_USERNAME/sales-forecasting-mlops.dvc\n",
    "\n",
    "# Set credentials\n",
    "dvc remote modify origin --local auth basic\n",
    "dvc remote modify origin --local user YOUR_USERNAME\n",
    "dvc remote modify origin --local password YOUR_TOKEN\n",
    "\n",
    "# Set as default\n",
    "dvc remote default origin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check DVC configuration\n",
    "result = subprocess.run(['dvc', 'remote', 'list'], capture_output=True, text=True)\n",
    "print(\"DVC Remotes:\")\n",
    "print(result.stdout if result.returncode == 0 else \"âŒ No remotes configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Push Data to Remote\n",
    "\n",
    "Upload data to DagsHub:\n",
    "\n",
    "```bash\n",
    "dvc push\n",
    "```\n",
    "\n",
    "This uploads actual data files to DagsHub storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Simulate Data Update\n",
    "\n",
    "Let's create a new version of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate larger dataset (v2)\n",
    "print(\"ðŸ“Š Generating updated dataset...\")\n",
    "result = subprocess.run(\n",
    "    ['python', 'data/generate_data.py', '--rows', '20000', '--output', 'data/raw/sales_data.csv'],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"âœ… New data generated (20,000 rows)\")\n",
    "    \n",
    "    # Check file size\n",
    "    size_mb = os.path.getsize('data/raw/sales_data.csv') / 1024 / 1024\n",
    "    print(f\"   File size: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(f\"âŒ Error: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now track the new version:\n",
    "\n",
    "```bash\n",
    "# Track new version\n",
    "dvc add data/raw/sales_data.csv\n",
    "\n",
    "# Notice the .dvc file changed (different MD5)\n",
    "git diff data/raw/sales_data.csv.dvc\n",
    "\n",
    "# Commit the change\n",
    "git add data/raw/sales_data.csv.dvc\n",
    "git commit -m \"Update sales data v2 - 20,000 rows\"\n",
    "\n",
    "# Push to DVC remote\n",
    "dvc push\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Switch Between Versions\n",
    "\n",
    "The magic of DVC - time travel for data!\n",
    "\n",
    "```bash\n",
    "# See Git history\n",
    "git log --oneline data/raw/sales_data.csv.dvc\n",
    "\n",
    "# Output:\n",
    "# abc123 Update sales data v2 - 20,000 rows\n",
    "# def456 Add sales data v1 - 10,000 rows\n",
    "\n",
    "# Switch to v1\n",
    "git checkout def456 data/raw/sales_data.csv.dvc\n",
    "dvc checkout\n",
    "\n",
    "# Now you have v1 data!\n",
    "wc -l data/raw/sales_data.csv\n",
    "# Output: 10001 (10,000 rows + header)\n",
    "\n",
    "# Switch back to v2\n",
    "git checkout main data/raw/sales_data.csv.dvc\n",
    "dvc checkout\n",
    "\n",
    "# Now you have v2 data!\n",
    "wc -l data/raw/sales_data.csv\n",
    "# Output: 20001 (20,000 rows + header)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: DVC Pipelines (Advanced)\n",
    "\n",
    "Track data processing pipelines:\n",
    "\n",
    "```bash\n",
    "# Define a preprocessing stage\n",
    "dvc run -n preprocess \\\n",
    "    -d data/raw/sales_data.csv \\\n",
    "    -o data/processed/features.csv \\\n",
    "    python src/data/data_processor.py\n",
    "```\n",
    "\n",
    "This creates `dvc.yaml`:\n",
    "```yaml\n",
    "stages:\n",
    "  preprocess:\n",
    "    cmd: python src/data/data_processor.py\n",
    "    deps:\n",
    "      - data/raw/sales_data.csv\n",
    "    outs:\n",
    "      - data/processed/features.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if dvc.yaml exists\n",
    "if os.path.exists('dvc.yaml'):\n",
    "    print(\"âœ… DVC pipeline exists\")\n",
    "    with open('dvc.yaml', 'r') as f:\n",
    "        print(\"\\nðŸ“„ Pipeline:\")\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(\"â„¹ï¸ No DVC pipeline yet (optional)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: DVC in Airflow\n",
    "\n",
    "How to use DVC in production pipelines:\n",
    "\n",
    "```python\n",
    "# In Airflow DAG\n",
    "from airflow.operators.bash import BashOperator\n",
    "\n",
    "pull_data = BashOperator(\n",
    "    task_id='dvc_pull',\n",
    "    bash_command='cd /path/to/project && dvc pull',\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "train_model = PythonOperator(\n",
    "    task_id='train',\n",
    "    python_callable=train_function,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "pull_data >> train_model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Real-World Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate versioning benefits\n",
    "print(\"ðŸ“ˆ Data Versioning Benefits:\\n\")\n",
    "\n",
    "versions = [\n",
    "    {\"date\": \"2024-01-01\", \"rows\": 10000, \"model_rmse\": 1250, \"commit\": \"abc123\"},\n",
    "    {\"date\": \"2024-02-01\", \"rows\": 15000, \"model_rmse\": 1100, \"commit\": \"def456\"},\n",
    "    {\"date\": \"2024-03-01\", \"rows\": 20000, \"model_rmse\": 980, \"commit\": \"ghi789\"},\n",
    "]\n",
    "\n",
    "df_versions = pd.DataFrame(versions)\n",
    "display(df_versions)\n",
    "\n",
    "print(\"\\nðŸ’¡ With DVC:\")\n",
    "print(\"  1. Can reproduce any model (just checkout the commit)\")\n",
    "print(\"  2. Know exactly which data trained which model\")\n",
    "print(\"  3. Team members get same data with 'dvc pull'\")\n",
    "print(\"  4. No 'sales_data_final_v2_actually_final.csv' nonsense!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… DVC Workflow Summary\n",
    "\n",
    "### Daily Workflow:\n",
    "```bash\n",
    "# 1. Get latest code and data\n",
    "git pull\n",
    "dvc pull\n",
    "\n",
    "# 2. Make changes to data\n",
    "python data/generate_data.py --rows 50000\n",
    "\n",
    "# 3. Track with DVC\n",
    "dvc add data/raw/sales_data.csv\n",
    "\n",
    "# 4. Commit to Git\n",
    "git add data/raw/sales_data.csv.dvc\n",
    "git commit -m \"Update data to 50k rows\"\n",
    "\n",
    "# 5. Push everything\n",
    "git push\n",
    "dvc push\n",
    "```\n",
    "\n",
    "### Why This Matters for MLOps:\n",
    "- ðŸ”„ **Reproducibility**: Exact data version for each model\n",
    "- ðŸ’¾ **Storage Efficient**: Git stores only metadata\n",
    "- ðŸ‘¥ **Team Collaboration**: Everyone gets same data\n",
    "- ðŸ“Š **Data Lineage**: Track data evolution\n",
    "- ðŸš€ **CI/CD Ready**: Automatic data pulls in pipelines\n",
    "\n",
    "### Common Commands:\n",
    "```bash\n",
    "dvc add <file>              # Track file\n",
    "dvc push                    # Upload to remote\n",
    "dvc pull                    # Download from remote\n",
    "dvc checkout                # Get data for current commit\n",
    "dvc status                  # Check if data changed\n",
    "dvc repro                   # Run pipeline\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** `06_Airflow_Pipeline_Development.ipynb` - Automate everything!\n",
    "\n",
    "**Â© 2024 Amey Talkatkar**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
