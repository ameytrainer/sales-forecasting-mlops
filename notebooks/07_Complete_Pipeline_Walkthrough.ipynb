{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Notebook 7: Complete MLOps Pipeline Walkthrough\n",
    "\n",
    "**Author:** Amey Talkatkar | **Course:** MLOps with Agentic AI\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "- Execute complete end-to-end MLOps pipeline\n",
    "- Integrate all components (DVC, MLflow, Airflow, FastAPI)\n",
    "- Understand production workflow from data to deployment\n",
    "- Verify each stage with real outputs\n",
    "- Troubleshoot issues in integrated system\n",
    "- Understand the full MLOps lifecycle\n",
    "\n",
    "## üî• The Problem (Final Boss!)\n",
    "\n",
    "You've learned:\n",
    "- Notebook 1: EDA\n",
    "- Notebook 2: Feature Engineering\n",
    "- Notebook 3: Model Training\n",
    "- Notebook 4: MLflow Tracking\n",
    "- Notebook 5: DVC Versioning\n",
    "- Notebook 6: Airflow Orchestration\n",
    "\n",
    "**But how do they all work TOGETHER?** ü§î\n",
    "\n",
    "Today: Connect all dots! Data ‚Üí Training ‚Üí Tracking ‚Üí Versioning ‚Üí Orchestration ‚Üí Deployment\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Pipeline Overview\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                    COMPLETE MLOPS PIPELINE                  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "1. DATA VERSIONING (DVC)\n",
    "   ‚îî‚îÄ> Track data changes in Git-like manner\n",
    "   \n",
    "2. DATA PREPARATION (Python)\n",
    "   ‚îî‚îÄ> Load from DVC ‚Üí Validate ‚Üí Engineer Features\n",
    "   \n",
    "3. MODEL TRAINING (scikit-learn, XGBoost)\n",
    "   ‚îî‚îÄ> Train 3 models in parallel\n",
    "   \n",
    "4. EXPERIMENT TRACKING (MLflow)\n",
    "   ‚îî‚îÄ> Log params, metrics, artifacts\n",
    "   \n",
    "5. MODEL REGISTRY (MLflow)\n",
    "   ‚îî‚îÄ> Register ‚Üí Staging ‚Üí Production\n",
    "   \n",
    "6. ORCHESTRATION (Airflow)\n",
    "   ‚îî‚îÄ> Automate entire workflow\n",
    "   \n",
    "7. DEPLOYMENT (FastAPI)\n",
    "   ‚îî‚îÄ> Serve predictions via REST API\n",
    "   \n",
    "8. MONITORING (Streamlit)\n",
    "   ‚îî‚îÄ> Visualize metrics and performance\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Change to project root\n",
    "os.chdir('..')\n",
    "print(f\"üìÇ Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Check services\n",
    "def check_service(name, url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=3)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"‚úÖ {name}: Running\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  {name}: Responding but status {response.status_code}\")\n",
    "            return False\n",
    "    except:\n",
    "        print(f\"‚ùå {name}: Not running\")\n",
    "        return False\n",
    "\n",
    "print(\"\\nüîç Checking Services...\")\n",
    "airflow_ok = check_service(\"Airflow\", \"http://localhost:8080/health\")\n",
    "api_ok = check_service(\"FastAPI\", \"http://localhost:8000/health\")\n",
    "dashboard_ok = check_service(\"Streamlit\", \"http://localhost:8501\")\n",
    "\n",
    "if not all([airflow_ok, api_ok, dashboard_ok]):\n",
    "    print(\"\\n‚ö†Ô∏è  Some services not running. Start them:\")\n",
    "    print(\"  airflow standalone &\")\n",
    "    print(\"  uvicorn api.main:app --host 0.0.0.0 --port 8000 &\")\n",
    "    print(\"  streamlit run dashboard/app.py &\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Data Versioning with DVC\n",
    "\n",
    "First, ensure data is tracked and versioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Stage 1: Data Versioning\\n\")\n",
    "\n",
    "# Check if data exists\n",
    "data_file = 'data/raw/sales_data.csv'\n",
    "dvc_file = f'{data_file}.dvc'\n",
    "\n",
    "if not os.path.exists(data_file):\n",
    "    print(\"üîÑ Generating fresh data...\")\n",
    "    result = subprocess.run(\n",
    "        ['python', 'data/generate_data.py', '--rows', '10000', '--output', data_file],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    print(result.stdout)\n",
    "\n",
    "# Check DVC tracking\n",
    "if os.path.exists(dvc_file):\n",
    "    print(f\"‚úÖ Data tracked with DVC: {dvc_file}\")\n",
    "    \n",
    "    # Read DVC metadata\n",
    "    import yaml\n",
    "    with open(dvc_file, 'r') as f:\n",
    "        dvc_meta = yaml.safe_load(f)\n",
    "    print(f\"   MD5: {dvc_meta['outs'][0]['md5']}\")\n",
    "    print(f\"   Size: {dvc_meta['outs'][0]['size']:,} bytes\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Data not tracked with DVC\")\n",
    "    print(\"   Run: dvc add data/raw/sales_data.csv\")\n",
    "\n",
    "# Load and preview data\n",
    "df = pd.read_csv(data_file, parse_dates=['date'])\n",
    "print(f\"\\nüìä Dataset: {len(df):,} rows √ó {len(df.columns)} columns\")\n",
    "print(f\"   Date range: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "print(f\"   Regions: {', '.join(df['region'].unique())}\")\n",
    "print(f\"   Products: {', '.join(df['product'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Feature Engineering Pipeline\n",
    "\n",
    "Transform raw data into ML-ready features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß Stage 2: Feature Engineering\\n\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Create lag features\n",
    "print(\"Creating lag features...\")\n",
    "for lag in [1, 7, 30]:\n",
    "    df[f'sales_lag_{lag}'] = df.groupby(['region', 'product'])['sales'].shift(lag)\n",
    "\n",
    "# Rolling features\n",
    "print(\"Creating rolling window features...\")\n",
    "for window in [7, 30]:\n",
    "    df[f'sales_rolling_mean_{window}'] = df.groupby(['region', 'product'])['sales'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "    )\n",
    "\n",
    "# One-hot encoding\n",
    "print(\"Encoding categorical variables...\")\n",
    "df_encoded = pd.get_dummies(df, columns=['region', 'product', 'season'], drop_first=True)\n",
    "\n",
    "# Define features\n",
    "feature_cols = [\n",
    "    'price', 'quantity', 'month', 'day_of_week',\n",
    "    'sales_lag_1', 'sales_lag_7', 'sales_lag_30',\n",
    "    'sales_rolling_mean_7', 'sales_rolling_mean_30',\n",
    "    'is_weekend',\n",
    "] + [col for col in df_encoded.columns if col.startswith(('region_', 'product_', 'season_'))]\n",
    "\n",
    "# Drop NaN rows\n",
    "df_clean = df_encoded.dropna(subset=feature_cols)\n",
    "X = df_clean[feature_cols]\n",
    "y = df_clean['sales']\n",
    "\n",
    "# Train/test split\n",
    "print(\"Splitting data...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=False\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "print(\"Scaling features...\")\n",
    "numerical_cols = ['price', 'quantity', 'month', 'day_of_week'] + \\\n",
    "                 [col for col in feature_cols if 'lag' in col or 'rolling' in col]\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# Save processed data\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "X_train.to_csv('data/processed/X_train.csv', index=False)\n",
    "X_test.to_csv('data/processed/X_test.csv', index=False)\n",
    "y_train.to_csv('data/processed/y_train.csv', index=False, header=True)\n",
    "y_test.to_csv('data/processed/y_test.csv', index=False, header=True)\n",
    "joblib.dump(scaler, 'data/processed/scaler.joblib')\n",
    "\n",
    "print(f\"\\n‚úÖ Feature engineering complete:\")\n",
    "print(f\"   Train: {len(X_train):,} samples\")\n",
    "print(f\"   Test:  {len(X_test):,} samples\")\n",
    "print(f\"   Features: {len(feature_cols)}\")\n",
    "print(f\"   Saved to: data/processed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Model Training with MLflow Tracking\n",
    "\n",
    "Train multiple models and track with MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ü§ñ Stage 3: Model Training with MLflow\\n\")\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Configure MLflow\n",
    "mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI', 'http://localhost:5000'))\n",
    "mlflow.set_experiment('complete_pipeline_demo')\n",
    "\n",
    "# Training function\n",
    "def train_and_log_model(model, model_name, model_type):\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_{datetime.now():%Y%m%d_%H%M}\"):\n",
    "        # Log model type\n",
    "        mlflow.log_param(\"model_type\", model_type)\n",
    "        \n",
    "        # Log hyperparameters\n",
    "        if hasattr(model, 'get_params'):\n",
    "            mlflow.log_params(model.get_params())\n",
    "        \n",
    "        # Train\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            \"rmse\": rmse,\n",
    "            \"mae\": mae,\n",
    "            \"r2_score\": r2,\n",
    "            \"train_time_seconds\": train_time\n",
    "        })\n",
    "        \n",
    "        # Log model\n",
    "        if model_type == \"XGBoost\":\n",
    "            mlflow.xgboost.log_model(model, \"model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        print(f\"‚úÖ {model_name}: RMSE=${rmse:,.2f}, R¬≤={r2:.4f}, Time={train_time:.2f}s\")\n",
    "        \n",
    "        return {\n",
    "            'run_id': mlflow.active_run().info.run_id,\n",
    "            'model_name': model_name,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'r2': r2\n",
    "        }\n",
    "\n",
    "# Train models\n",
    "results = []\n",
    "\n",
    "print(\"Training Linear Regression...\")\n",
    "lr_result = train_and_log_model(\n",
    "    LinearRegression(),\n",
    "    \"linear_regression\",\n",
    "    \"LinearRegression\"\n",
    ")\n",
    "results.append(lr_result)\n",
    "\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "rf_result = train_and_log_model(\n",
    "    RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),\n",
    "    \"random_forest\",\n",
    "    \"RandomForest\"\n",
    ")\n",
    "results.append(rf_result)\n",
    "\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "xgb_result = train_and_log_model(\n",
    "    XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, n_jobs=-1, verbosity=0),\n",
    "    \"xgboost\",\n",
    "    \"XGBoost\"\n",
    ")\n",
    "results.append(xgb_result)\n",
    "\n",
    "# Compare results\n",
    "results_df = pd.DataFrame(results).sort_values('rmse')\n",
    "print(\"\\nüìä Model Comparison:\")\n",
    "display(results_df[['model_name', 'rmse', 'mae', 'r2']])\n",
    "\n",
    "best_model = results_df.iloc[0]\n",
    "print(f\"\\nüèÜ Best Model: {best_model['model_name']}\")\n",
    "print(f\"   RMSE: ${best_model['rmse']:,.2f}\")\n",
    "print(f\"   Run ID: {best_model['run_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4: Model Registry & Promotion\n",
    "\n",
    "Register best model and promote to production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Stage 4: Model Registry\\n\")\n",
    "\n",
    "# Register best model\n",
    "MODEL_NAME = \"sales_forecasting_production\"\n",
    "best_run_id = best_model['run_id']\n",
    "model_uri = f\"runs:/{best_run_id}/model\"\n",
    "\n",
    "try:\n",
    "    model_version = mlflow.register_model(model_uri, MODEL_NAME)\n",
    "    print(f\"‚úÖ Model registered:\")\n",
    "    print(f\"   Name: {model_version.name}\")\n",
    "    print(f\"   Version: {model_version.version}\")\n",
    "    print(f\"   Current Stage: {model_version.current_stage}\")\n",
    "    \n",
    "    # Transition to Staging\n",
    "    client = mlflow.MlflowClient()\n",
    "    client.transition_model_version_stage(\n",
    "        name=MODEL_NAME,\n",
    "        version=model_version.version,\n",
    "        stage=\"Staging\"\n",
    "    )\n",
    "    print(f\"\\n‚úÖ Transitioned to Staging\")\n",
    "    \n",
    "    # Simulate validation tests passing\n",
    "    print(\"\\nüß™ Running validation tests...\")\n",
    "    time.sleep(2)\n",
    "    print(\"   ‚úÖ Data quality check: PASS\")\n",
    "    print(\"   ‚úÖ Model accuracy check: PASS\")\n",
    "    print(\"   ‚úÖ Inference time check: PASS\")\n",
    "    \n",
    "    # Promote to Production\n",
    "    client.transition_model_version_stage(\n",
    "        name=MODEL_NAME,\n",
    "        version=model_version.version,\n",
    "        stage=\"Production\",\n",
    "        archive_existing_versions=True\n",
    "    )\n",
    "    print(f\"\\nüöÄ Model promoted to PRODUCTION!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error: {e}\")\n",
    "    print(\"   Continuing with existing model...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5: API Deployment & Testing\n",
    "\n",
    "Test FastAPI serving predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üåê Stage 5: API Testing\\n\")\n",
    "\n",
    "API_URL = \"http://localhost:8000\"\n",
    "\n",
    "# Test health endpoint\n",
    "try:\n",
    "    response = requests.get(f\"{API_URL}/health\")\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ API Health Check: OK\")\n",
    "        print(f\"   Response: {response.json()}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  API Health Check: Status {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå API not reachable: {e}\")\n",
    "    print(\"   Start API: uvicorn api.main:app --host 0.0.0.0 --port 8000 &\")\n",
    "\n",
    "# Test prediction endpoint (if API is running)\n",
    "try:\n",
    "    # Sample prediction request\n",
    "    sample_data = {\n",
    "        \"date\": \"2024-12-01\",\n",
    "        \"region\": \"North\",\n",
    "        \"product\": \"Electronics\",\n",
    "        \"price\": 299.99,\n",
    "        \"quantity\": 50\n",
    "    }\n",
    "    \n",
    "    print(\"\\nüîÆ Testing Prediction Endpoint...\")\n",
    "    print(f\"   Input: {sample_data}\")\n",
    "    \n",
    "    response = requests.post(f\"{API_URL}/predict\", json=sample_data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        prediction = response.json()\n",
    "        print(f\"\\n‚úÖ Prediction successful:\")\n",
    "        print(f\"   Predicted Sales: ${prediction.get('predicted_sales', 'N/A'):,.2f}\")\n",
    "        print(f\"   Confidence: {prediction.get('confidence', 'N/A')}\")\n",
    "        print(f\"   Model: {prediction.get('model_version', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Prediction failed: {response.status_code}\")\n",
    "        print(f\"   Response: {response.text}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not test predictions: {e}\")\n",
    "    print(\"   Ensure /predict endpoint is implemented in api/main.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6: Airflow Pipeline Trigger\n",
    "\n",
    "Trigger the automated pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úàÔ∏è Stage 6: Airflow Pipeline\\n\")\n",
    "\n",
    "AIRFLOW_URL = \"http://localhost:8080\"\n",
    "AIRFLOW_USER = \"admin\"\n",
    "AIRFLOW_PASSWORD = \"admin123\"\n",
    "\n",
    "# Check if DAG exists\n",
    "try:\n",
    "    response = requests.get(\n",
    "        f\"{AIRFLOW_URL}/api/v1/dags\",\n",
    "        auth=(AIRFLOW_USER, AIRFLOW_PASSWORD)\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        dags = response.json().get('dags', [])\n",
    "        dag_ids = [dag['dag_id'] for dag in dags]\n",
    "        \n",
    "        print(f\"‚úÖ Connected to Airflow\")\n",
    "        print(f\"   Available DAGs: {len(dag_ids)}\")\n",
    "        \n",
    "        # Look for ML training DAG\n",
    "        ml_dags = [d for d in dag_ids if 'ml' in d.lower() or 'training' in d.lower()]\n",
    "        if ml_dags:\n",
    "            print(f\"   ML DAGs found: {', '.join(ml_dags)}\")\n",
    "            \n",
    "            # Trigger first ML DAG\n",
    "            dag_id = ml_dags[0]\n",
    "            print(f\"\\nüöÄ Triggering DAG: {dag_id}\")\n",
    "            \n",
    "            trigger_response = requests.post(\n",
    "                f\"{AIRFLOW_URL}/api/v1/dags/{dag_id}/dagRuns\",\n",
    "                auth=(AIRFLOW_USER, AIRFLOW_PASSWORD),\n",
    "                json={\"conf\": {\"triggered_by\": \"notebook_07\"}}\n",
    "            )\n",
    "            \n",
    "            if trigger_response.status_code == 200:\n",
    "                dag_run = trigger_response.json()\n",
    "                print(f\"‚úÖ DAG run created:\")\n",
    "                print(f\"   Run ID: {dag_run.get('dag_run_id')}\")\n",
    "                print(f\"   State: {dag_run.get('state')}\")\n",
    "                print(f\"\\n   View in UI: {AIRFLOW_URL}/dags/{dag_id}/grid\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Failed to trigger: {trigger_response.status_code}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  No ML training DAGs found\")\n",
    "            print(\"   Create DAG in ~/airflow/dags/ml_training_pipeline.py\")\n",
    "    else:\n",
    "        print(f\"‚ùå Could not connect to Airflow: {response.status_code}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Airflow error: {e}\")\n",
    "    print(\"   Ensure Airflow is running: airflow standalone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7: Dashboard Verification\n",
    "\n",
    "Check Streamlit dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Stage 7: Dashboard Check\\n\")\n",
    "\n",
    "DASHBOARD_URL = \"http://localhost:8501\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(DASHBOARD_URL, timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ Streamlit Dashboard: Running\")\n",
    "        print(f\"   URL: {DASHBOARD_URL}\")\n",
    "        print(\"\\n   Available pages:\")\n",
    "        print(\"   ‚Ä¢ Main Dashboard\")\n",
    "        print(\"   ‚Ä¢ Model Comparison\")\n",
    "        print(\"   ‚Ä¢ Experiment Tracking\")\n",
    "        print(\"   ‚Ä¢ Predictions\")\n",
    "        print(\"   ‚Ä¢ Data Drift Monitoring\")\n",
    "        print(\"   ‚Ä¢ System Health\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Dashboard responding but status {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Dashboard not reachable: {e}\")\n",
    "    print(\"   Start dashboard: streamlit run dashboard/app.py &\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Pipeline Summary & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"                    üöÄ MLOPS PIPELINE EXECUTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary = {\n",
    "    \"Stage\": [\n",
    "        \"1. Data Versioning\",\n",
    "        \"2. Feature Engineering\",\n",
    "        \"3. Model Training\",\n",
    "        \"4. Model Registry\",\n",
    "        \"5. API Deployment\",\n",
    "        \"6. Airflow Pipeline\",\n",
    "        \"7. Dashboard\"\n",
    "    ],\n",
    "    \"Component\": [\n",
    "        \"DVC\",\n",
    "        \"scikit-learn\",\n",
    "        \"MLflow Tracking\",\n",
    "        \"MLflow Registry\",\n",
    "        \"FastAPI\",\n",
    "        \"Apache Airflow\",\n",
    "        \"Streamlit\"\n",
    "    ],\n",
    "    \"Status\": [\n",
    "        \"‚úÖ Data tracked\" if os.path.exists(dvc_file) else \"‚ö†Ô∏è  Setup needed\",\n",
    "        \"‚úÖ Features ready\",\n",
    "        f\"‚úÖ {len(results)} models trained\",\n",
    "        \"‚úÖ Model in Production\",\n",
    "        \"‚úÖ Running\" if api_ok else \"‚ö†Ô∏è  Not running\",\n",
    "        \"‚úÖ Running\" if airflow_ok else \"‚ö†Ô∏è  Not running\",\n",
    "        \"‚úÖ Running\" if dashboard_ok else \"‚ö†Ô∏è  Not running\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "display(summary_df)\n",
    "\n",
    "print(\"\\nüìà Key Metrics:\")\n",
    "print(f\"   Dataset Size: {len(df):,} rows\")\n",
    "print(f\"   Features Created: {len(feature_cols)}\")\n",
    "print(f\"   Models Trained: {len(results)}\")\n",
    "print(f\"   Best Model: {best_model['model_name']}\")\n",
    "print(f\"   Best RMSE: ${best_model['rmse']:,.2f}\")\n",
    "print(f\"   Best R¬≤ Score: {best_model['r2']:.4f}\")\n",
    "\n",
    "print(\"\\nüîó Access Points:\")\n",
    "print(f\"   Airflow UI:  http://localhost:8080\")\n",
    "print(f\"   MLflow UI:   {os.getenv('MLFLOW_TRACKING_URI', 'Not configured')}\")\n",
    "print(f\"   FastAPI:     http://localhost:8000/docs\")\n",
    "print(f\"   Dashboard:   http://localhost:8501\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì What We Accomplished\n",
    "\n",
    "### Complete MLOps Lifecycle:\n",
    "\n",
    "1. **Data Management** ‚úÖ\n",
    "   - Versioned with DVC\n",
    "   - Tracked in Git\n",
    "   - Reproducible\n",
    "\n",
    "2. **Feature Engineering** ‚úÖ\n",
    "   - Lag features (1, 7, 30 days)\n",
    "   - Rolling statistics\n",
    "   - Categorical encoding\n",
    "   - Feature scaling\n",
    "\n",
    "3. **Model Training** ‚úÖ\n",
    "   - 3 models compared\n",
    "   - All metrics logged to MLflow\n",
    "   - Best model identified\n",
    "\n",
    "4. **Model Registry** ‚úÖ\n",
    "   - Model registered\n",
    "   - Staging validation\n",
    "   - Production promotion\n",
    "   - Version controlled\n",
    "\n",
    "5. **Deployment** ‚úÖ\n",
    "   - REST API serving\n",
    "   - Real-time predictions\n",
    "   - Health monitoring\n",
    "\n",
    "6. **Orchestration** ‚úÖ\n",
    "   - Automated workflows\n",
    "   - Error handling\n",
    "   - Scheduled execution\n",
    "\n",
    "7. **Monitoring** ‚úÖ\n",
    "   - Performance dashboards\n",
    "   - Experiment tracking\n",
    "   - System health checks\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Production Readiness Checklist\n",
    "\n",
    "- [x] Data versioning (DVC)\n",
    "- [x] Experiment tracking (MLflow)\n",
    "- [x] Model registry (MLflow)\n",
    "- [x] Pipeline automation (Airflow)\n",
    "- [x] API deployment (FastAPI)\n",
    "- [x] Monitoring dashboard (Streamlit)\n",
    "- [ ] CI/CD pipeline (GitHub Actions) ‚Üí Next phase\n",
    "- [ ] Data drift detection ‚Üí Next phase\n",
    "- [ ] A/B testing ‚Üí Next phase\n",
    "- [ ] Auto-retraining ‚Üí Next phase\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Key Takeaways\n",
    "\n",
    "### Why This Architecture?\n",
    "\n",
    "**Before MLOps:**\n",
    "- Manual scripts run by Sarah at 2 AM\n",
    "- No tracking of experiments\n",
    "- Can't reproduce results\n",
    "- Models lost after 3 months\n",
    "- No idea which data trained which model\n",
    "\n",
    "**After MLOps:**\n",
    "- Fully automated pipelines\n",
    "- Every experiment tracked\n",
    "- 100% reproducible\n",
    "- Models versioned forever\n",
    "- Complete lineage: Data ‚Üí Features ‚Üí Model ‚Üí Predictions\n",
    "\n",
    "### Production Benefits:\n",
    "\n",
    "1. **Reliability**: Automatic retries, error handling\n",
    "2. **Reproducibility**: Git + DVC + MLflow = complete history\n",
    "3. **Scalability**: Add more models/features easily\n",
    "4. **Collaboration**: Team sees same experiments\n",
    "5. **Compliance**: Full audit trail\n",
    "6. **Speed**: Deploy in minutes, not days\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Next Steps\n",
    "\n",
    "### Immediate:\n",
    "1. Add more DAGs for batch predictions\n",
    "2. Implement data drift detection\n",
    "3. Set up CI/CD with GitHub Actions\n",
    "4. Add unit tests (pytest)\n",
    "\n",
    "### Advanced:\n",
    "1. Multi-model serving (A/B testing)\n",
    "2. Auto-retraining on drift detection\n",
    "3. Kubernetes deployment\n",
    "4. Model explainability (SHAP)\n",
    "5. Feature store integration\n",
    "\n",
    "---\n",
    "\n",
    "## üèÜ Congratulations!\n",
    "\n",
    "You've built a **production-ready MLOps pipeline** from scratch!\n",
    "\n",
    "This is what top tech companies use:\n",
    "- ‚úÖ Google (TFX)\n",
    "- ‚úÖ Netflix (Metaflow)\n",
    "- ‚úÖ Uber (Michelangelo)\n",
    "- ‚úÖ Airbnb (BigHead)\n",
    "\n",
    "You now understand:\n",
    "- Why each component exists\n",
    "- How they integrate\n",
    "- When to use what\n",
    "- How to debug issues\n",
    "\n",
    "**This knowledge is what you'll use every day as an MLOps engineer!**\n",
    "\n",
    "---\n",
    "\n",
    "**¬© 2024 Amey Talkatkar** | MLOps with Agentic AI - Advanced Certification\n",
    "\n",
    "**Course Modules Covered:**\n",
    "- ‚úÖ Module 1: Python & MLOps Foundations\n",
    "- üîÑ Module 2: Modern Cloud-Native MLOps (In Progress)\n",
    "- ‚è≥ Module 3: Cloud & Productionization (Coming Soon)\n",
    "- ‚è≥ Module 4: Agentic AI & LLMOps (Coming Soon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}