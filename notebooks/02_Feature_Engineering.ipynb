{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîß Notebook 2: Feature Engineering\n",
    "\n",
    "**Author:** Amey Talkatkar | **Course:** MLOps with Agentic AI\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "- Transform raw data into ML-ready features\n",
    "- Create lag and rolling window features\n",
    "- Encode categorical variables\n",
    "- Scale numerical features\n",
    "- Handle train/test split properly\n",
    "- Save processed data for DVC tracking\n",
    "\n",
    "## üî• The Problem\n",
    "A DS trained a model on raw data:\n",
    "- Forgot to encode categories ‚Üí Model crashed\n",
    "- Scaled on all data ‚Üí Data leakage!\n",
    "- No lag features ‚Üí Model couldn't capture trends\n",
    "- Result: Poor accuracy in production\n",
    "\n",
    "**Solution: Proper feature engineering!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/sales_data.csv', parse_dates=['date'])\n",
    "print(f\"Loaded: {len(df):,} rows\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Lag Features\n",
    "Capture historical patterns (yesterday's sales predict today's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date for time series operations\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Create lag features (previous days' sales)\n",
    "for lag in [1, 7, 30]:\n",
    "    df[f'sales_lag_{lag}'] = df.groupby(['region', 'product'])['sales'].shift(lag)\n",
    "\n",
    "# Rolling window features (average of last N days)\n",
    "for window in [7, 30]:\n",
    "    df[f'sales_rolling_mean_{window}'] = df.groupby(['region', 'product'])['sales'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "    )\n",
    "    df[f'sales_rolling_std_{window}'] = df.groupby(['region', 'product'])['sales'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).std()\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Lag features created\")\n",
    "print(f\"New columns: {[col for col in df.columns if 'lag' in col or 'rolling' in col]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for region and product\n",
    "df_encoded = pd.get_dummies(df, columns=['region', 'product', 'season'], drop_first=True)\n",
    "\n",
    "print(f\"‚úÖ Categorical encoding complete\")\n",
    "print(f\"Original columns: {len(df.columns)}\")\n",
    "print(f\"After encoding: {len(df_encoded.columns)}\")\n",
    "print(f\"\\nNew binary columns: {[col for col in df_encoded.columns if col.startswith(('region_', 'product_', 'season_'))]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Feature Selection\n",
    "Choose features for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "feature_cols = [\n",
    "    # Numerical features\n",
    "    'price', 'quantity', 'month', 'day_of_week',\n",
    "    # Lag features\n",
    "    'sales_lag_1', 'sales_lag_7', 'sales_lag_30',\n",
    "    # Rolling features\n",
    "    'sales_rolling_mean_7', 'sales_rolling_mean_30',\n",
    "    'sales_rolling_std_7', 'sales_rolling_std_30',\n",
    "    # Binary features\n",
    "    'is_weekend',\n",
    "] + [col for col in df_encoded.columns if col.startswith(('region_', 'product_', 'season_'))]\n",
    "\n",
    "target_col = 'sales'\n",
    "\n",
    "print(f\"‚úÖ Selected {len(feature_cols)} features\")\n",
    "print(f\"Target: {target_col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Handle Missing Values\n",
    "Lag features create NaN for first rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Missing values before: {df_encoded[feature_cols].isnull().sum().sum()}\")\n",
    "\n",
    "# Drop rows with missing lag features (first 30 days)\n",
    "df_clean = df_encoded.dropna(subset=feature_cols)\n",
    "\n",
    "print(f\"Missing values after: {df_clean[feature_cols].isnull().sum().sum()}\")\n",
    "print(f\"Rows remaining: {len(df_clean):,} ({len(df_clean)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train/Test Split\n",
    "‚ö†Ô∏è CRITICAL: Split BEFORE scaling to avoid data leakage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X and y\n",
    "X = df_clean[feature_cols]\n",
    "y = df_clean[target_col]\n",
    "\n",
    "# Split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=False  # No shuffle for time series!\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Train/Test Split:\")\n",
    "print(f\"   Train: {len(X_train):,} rows ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   Test:  {len(X_test):,} rows ({len(X_test)/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Feature Scaling\n",
    "Scale ONLY on train data, then transform test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns to scale\n",
    "numerical_cols = ['price', 'quantity', 'month', 'day_of_week'] + \\\n",
    "                 [col for col in feature_cols if 'lag' in col or 'rolling' in col]\n",
    "\n",
    "# Fit scaler on train data ONLY\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "\n",
    "# Transform test data with same scaler\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "print(\"‚úÖ Features scaled\")\n",
    "print(f\"   Scaled columns: {len(numerical_cols)}\")\n",
    "print(f\"   Mean after scaling: {X_train[numerical_cols].mean().mean():.6f} (should be ~0)\")\n",
    "print(f\"   Std after scaling: {X_train[numerical_cols].std().mean():.6f} (should be ~1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Feature Importance Analysis\n",
    "Which features are most useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick correlation with target\n",
    "correlations = X_train.corrwith(y_train).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlations.head(15).plot(kind='barh')\n",
    "plt.title('Top 15 Features by Correlation with Sales')\n",
    "plt.xlabel('Correlation')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 features:\")\n",
    "print(correlations.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save train/test splits\n",
    "X_train.to_csv('../data/processed/X_train.csv', index=False)\n",
    "X_test.to_csv('../data/processed/X_test.csv', index=False)\n",
    "y_train.to_csv('../data/processed/y_train.csv', index=False, header=True)\n",
    "y_test.to_csv('../data/processed/y_test.csv', index=False, header=True)\n",
    "\n",
    "# Save scaler for production use\n",
    "import joblib\n",
    "joblib.dump(scaler, '../data/processed/scaler.joblib')\n",
    "\n",
    "print(\"‚úÖ Processed data saved!\")\n",
    "print(\"   Location: ../data/processed/\")\n",
    "print(\"   Files: X_train.csv, X_test.csv, y_train.csv, y_test.csv, scaler.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "### What We Created:\n",
    "1. ‚úÖ **Lag Features**: sales_lag_1, sales_lag_7, sales_lag_30\n",
    "2. ‚úÖ **Rolling Features**: mean and std for 7 and 30 days\n",
    "3. ‚úÖ **Encoded Categoricals**: region, product, season\n",
    "4. ‚úÖ **Scaled Numericals**: StandardScaler fit on train only\n",
    "5. ‚úÖ **Train/Test Split**: 80/20, no shuffle (time series)\n",
    "\n",
    "### Why This Matters for MLOps:\n",
    "- üîÑ **Reproducibility**: Saved scaler ensures consistent transformations\n",
    "- üìä **No Data Leakage**: Scaled after split\n",
    "- üéØ **Feature Store Ready**: Clean, processed features\n",
    "- üìà **DVC Tracking**: Can version processed data\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** `03_Model_Training_Comparison.ipynb` - Train and compare 3 models\n",
    "\n",
    "**¬© 2024 Amey Talkatkar**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
