"""
Custom Airflow Operators

Custom operators for MLOps tasks:
- MLflowOperator: Interact with MLflow
- DVCOperator: Execute DVC commands
- ModelValidationOperator: Validate models
- DataQualityOperator: Check data quality

Author: Amey Talkatkar
Email: ameytalkatkar169@gmail.com
"""

from typing import Any, Dict, List, Optional
import subprocess
import logging

from airflow.models import BaseOperator
from airflow.utils.decorators import apply_defaults

import sys
sys.path.insert(0, '/home/ubuntu/sales-forecasting-mlops')

from src.config import get_settings
from src.data import DataValidator
from src.models import ModelRegistry

logger = logging.getLogger(__name__)


class DVCOperator(BaseOperator):
    """
    Execute DVC commands as Airflow operator.
    
    Usage:
        pull_data = DVCOperator(
            task_id='dvc_pull',
            command='pull',
            targets=['data/raw/sales_data.csv.dvc']
        )
    """
    
    template_fields = ['targets', 'command']
    
    @apply_defaults
    def __init__(
        self,
        command: str,
        targets: Optional[List[str]] = None,
        cwd: Optional[str] = None,
        *args,
        **kwargs
    ):
        """
        Initialize DVC operator.
        
        Args:
            command: DVC command (pull, push, add, etc.)
            targets: List of DVC files to operate on
            cwd: Working directory (defaults to project root)
        """
        super().__init__(*args, **kwargs)
        self.command = command
        self.targets = targets or []
        self.cwd = cwd or '/home/ubuntu/sales-forecasting-mlops'
    
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute DVC command."""
        logger.info(f"Executing DVC command: {self.command}")
        
        # Build command
        cmd = ['dvc', self.command]
        if self.targets:
            cmd.extend(self.targets)
        
        # Execute
        try:
            result = subprocess.run(
                cmd,
                cwd=self.cwd,
                capture_output=True,
                text=True,
                timeout=300,
            )
            
            if result.returncode != 0:
                logger.error(f"DVC command failed: {result.stderr}")
                raise RuntimeError(f"DVC {self.command} failed: {result.stderr}")
            
            logger.info(f"DVC command successful: {result.stdout}")
            
            return {
                'command': self.command,
                'targets': self.targets,
                'stdout': result.stdout,
                'returncode': result.returncode,
            }
            
        except subprocess.TimeoutExpired:
            logger.error("DVC command timed out")
            raise


class MLflowOperator(BaseOperator):
    """
    Interact with MLflow as Airflow operator.
    
    Usage:
        transition_model = MLflowOperator(
            task_id='transition_to_production',
            operation='transition_model',
            model_name='sales_forecasting',
            version=1,
            stage='Production'
        )
    """
    
    template_fields = ['model_name', 'version', 'stage']
    
    @apply_defaults
    def __init__(
        self,
        operation: str,
        model_name: Optional[str] = None,
        version: Optional[int] = None,
        stage: Optional[str] = None,
        *args,
        **kwargs
    ):
        """
        Initialize MLflow operator.
        
        Args:
            operation: Operation to perform (transition_model, get_model, etc.)
            model_name: Name of registered model
            version: Model version
            stage: Target stage (Staging, Production, Archived)
        """
        super().__init__(*args, **kwargs)
        self.operation = operation
        self.model_name = model_name
        self.version = version
        self.stage = stage
    
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute MLflow operation."""
        logger.info(f"Executing MLflow operation: {self.operation}")
        
        registry = ModelRegistry()
        
        if self.operation == 'transition_model':
            if not all([self.model_name, self.version, self.stage]):
                raise ValueError("transition_model requires model_name, version, and stage")
            
            registry.transition_model(self.model_name, self.version, self.stage)
            
            return {
                'operation': 'transition_model',
                'model_name': self.model_name,
                'version': self.version,
                'stage': self.stage,
            }
        
        elif self.operation == 'get_production_model':
            if not self.model_name:
                raise ValueError("get_production_model requires model_name")
            
            model_version = registry.get_production_model(self.model_name)
            
            return {
                'operation': 'get_production_model',
                'model_name': self.model_name,
                'version': model_version,
            }
        
        elif self.operation == 'archive_old_versions':
            if not self.model_name:
                raise ValueError("archive_old_versions requires model_name")
            
            keep_n = self.version if self.version else 3
            registry.archive_old_versions(self.model_name, keep_latest_n=keep_n)
            
            return {
                'operation': 'archive_old_versions',
                'model_name': self.model_name,
                'kept_versions': keep_n,
            }
        
        else:
            raise ValueError(f"Unknown operation: {self.operation}")


class DataQualityOperator(BaseOperator):
    """
    Check data quality as Airflow operator.
    
    Usage:
        validate_data = DataQualityOperator(
            task_id='validate_sales_data',
            filepath='data/raw/sales_data.csv',
            strict=True
        )
    """
    
    template_fields = ['filepath']
    
    @apply_defaults
    def __init__(
        self,
        filepath: str,
        strict: bool = False,
        fail_on_error: bool = True,
        *args,
        **kwargs
    ):
        """
        Initialize data quality operator.
        
        Args:
            filepath: Path to data file
            strict: Use strict validation rules
            fail_on_error: Fail task if validation fails
        """
        super().__init__(*args, **kwargs)
        self.filepath = filepath
        self.strict = strict
        self.fail_on_error = fail_on_error
    
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute data quality checks."""
        logger.info(f"Checking data quality: {self.filepath}")
        
        validator = DataValidator()
        
        # Load data
        from src.data import DataLoader
        loader = DataLoader()
        df = loader.load_csv(self.filepath)
        
        # Validate
        report = validator.validate_sales_data(df, strict=self.strict)
        
        # Log report
        readable_report = validator.generate_validation_report(report)
        logger.info(f"\n{readable_report}")
        
        # Fail if validation fails and flag is set
        if not report['is_valid'] and self.fail_on_error:
            raise ValueError(f"Data validation failed: {report['checks_failed']}")
        
        return {
            'is_valid': report['is_valid'],
            'row_count': report['row_count'],
            'checks_passed': len(report['checks_passed']),
            'checks_failed': len(report['checks_failed']),
            'warnings': len(report['warnings']),
        }


class ModelValidationOperator(BaseOperator):
    """
    Validate trained model before deployment.
    
    Usage:
        validate_model = ModelValidationOperator(
            task_id='validate_staging_model',
            model_name='sales_forecasting',
            version=1,
            tests=['accuracy', 'inference_time', 'resource_usage']
        )
    """
    
    template_fields = ['model_name', 'version']
    
    @apply_defaults
    def __init__(
        self,
        model_name: str,
        version: int,
        tests: Optional[List[str]] = None,
        *args,
        **kwargs
    ):
        """
        Initialize model validation operator.
        
        Args:
            model_name: Name of model to validate
            version: Model version
            tests: List of tests to run
        """
        super().__init__(*args, **kwargs)
        self.model_name = model_name
        self.version = version
        self.tests = tests or ['accuracy', 'inference_time']
    
    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute model validation tests."""
        logger.info(f"Validating model: {self.model_name} v{self.version}")
        
        test_results = {}
        
        # Accuracy test
        if 'accuracy' in self.tests:
            # In production, load model and test on validation set
            # For now, simulate
            test_results['accuracy'] = {
                'passed': True,
                'metric': 'rmse',
                'value': 85.5,
                'threshold': 100.0,
            }
        
        # Inference time test
        if 'inference_time' in self.tests:
            # In production, measure actual inference time
            test_results['inference_time'] = {
                'passed': True,
                'avg_ms': 45.2,
                'threshold_ms': 100.0,
            }
        
        # Resource usage test
        if 'resource_usage' in self.tests:
            test_results['resource_usage'] = {
                'passed': True,
                'memory_mb': 150.0,
                'threshold_mb': 500.0,
            }
        
        # Check if all tests passed
        all_passed = all(result.get('passed', False) for result in test_results.values())
        
        if not all_passed:
            failed_tests = [name for name, result in test_results.items() 
                          if not result.get('passed', False)]
            raise ValueError(f"Model validation failed: {failed_tests}")
        
        logger.info("âœ… All validation tests passed")
        
        return {
            'model_name': self.model_name,
            'version': self.version,
            'tests_run': self.tests,
            'test_results': test_results,
            'all_passed': all_passed,
        }


# Plugin registration
class CustomMLOpsPlugin:
    """Airflow plugin to register custom operators."""
    name = "custom_mlops_plugin"
    operators = [DVCOperator, MLflowOperator, DataQualityOperator, ModelValidationOperator]
